# Titanic Competition on Kaggle

## About this project
This project showcases my work for <a href='https://www.kaggle.com/competitions/titanic'>Kaggle Titanic Competition</a>.<br>
After completing some practical Kaggle courses, I was ready to use my new knowledge, build my first own model and paticipate in this beginner-friendly competition. I had 2 goals in my mind for this project: to apply as many new techniques that I've recently learned as I can and also to continously improve my predictions. The task involved predicting who survived the Titanic disaster based on passenger data such as age, sex, cabin number, class and more. The challenge became increasingly interesting as I got familiar with all the aspects of building better machine learning models.

## What did I learn?
- <b>Data Cleaning</b>: replacing missing data with useful informations
- <b>Data Preparation</b>: making changes to the data to further improve model performance
- <b>Hyperparameter Tuning</b>: experimenting different techniques to find optimal parameters for the model
- <b>Pipelines</b>: creating basic pipelines to bundle data preprocessing and model
- <b>Machine Learning Models</b>: understanding the basic concepts of some ML models (Linear Regression, Decision Tree, Random Forest, Gradient Boosting)
- <b>Model Validation</b>: exploring a variety of metrics to measure model performances (accuracy score, cross validation, confusion matrix)
- <b>Kaggle Competition</b>: becoming familiar with Kaggle platform and participating in a competition

## Tools
 - Python
 - Jupyter Notebook
 - Pandas
 - Seaborn
 - SciKit-Learn
 - Kaggle
